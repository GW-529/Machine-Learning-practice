{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯分类：\n",
    "特征值选取：不包含前面450个最高频率的词，词长1到5之间，不是数字，不是停用词，不超过10000个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按词频降序排序的训练集列表: [',', '，', '？', '的', '！', '：', ' ', '了', '是', '你', '“', '”', '有', '吗', '在', '中国', '如何', '什么', '怎么', '和', '为什么', '人', '-', '都', '不', '》', '《', '被', '对', '我', '美国', '、', '会', '年', '大', '看', '这', '游戏', '上', '手机', '能', '农村', '好', '最', '与', '上联', '下联', '5', '要', '新', '后', '还', '中', '就', '3', '汽车', '网友', '哪些', '将', '月', '让', '世界', '2018', '一个', '他', '—', '去', '谁', '日本', '俄罗斯', '如果', '又', '万', '2', '却', '买', '到', '王者', '说', '多', '也', '可以', '荣耀', '英雄', '个', '没有', '4', '来', '还是', '小', '·', '现在', '用', '做', '为', '房价', '10', '伊朗', '小米', '特朗普', '车', '把', 'SUV', '联盟', '呢', '日', '哪个', '国家', '给', '20', '活动', '怎样', '为何', '一', '詹姆斯', '以色列', '1', '她', '很', '岁', '火箭', 'NBA', '这个', '8', '6', '更', '旅游', '看待', '自己', '多少', '知道', '想', '腾讯', '到底', '…', '「', '」', '公司', '北京', '打', '这些', '市场', '比', '真的', '协议', '里', '华为', '吃', '怎么样', '印度', '下', '联想', '城市', '该', '）', '过', '马云', '（', '7', '玩家', '链', '科技', '买房', '高', '企业', '求生', '宝马', '银行', '第一', '出席', '之', '没', '区块', '我们', '大学', '再', '教育', '绝地', '出', '微信', '钱', '奥迪', '集团', '苹果', '技术', '孩子', '电影', '时', '股份', '发展', '｜', '勇士', '未来', '这么', '评价', '高考', '才', '投资', '国际', '成为', '骑士', '东方', '从', '总统', '吧', '前', '不是', '互联网', '戛纳', '季后赛', '支付宝', '航母', '叙利亚', '这样', '老师', '丰田', '+', '数据', '学生', '着', '品牌', '教师', '或', '那么', '经济', '文化', '上海', '就是', '美', '选择', '战机', '大家', '普京', '房子', '机器人', '还有', '上市', '歼', '价格', '号', '喜欢', '发动机', '韩国', '玩', '需要', '等', '是否', '不能', '学校', '这种', '万元', '级', '币', '太', '9', '猛龙', '亿', '而', '分', '全球', '可', '元', '走', '农业', '范冰冰', '成', '比赛', '伊核', '。', '黄金', '哪', '生活', '应该', '房地产', '不会', '老', '爱', '得', '已', '人工智能', '跑', '退出', '可能', '怎么办', '电影节', '系统', '但', '股票', '历史', '问题', 'RNG', '拿', '值得', '司机', '只', '时代', '地方', '战争', '全国', 'DNF', '15', '比特', '推荐', '智能', '导弹', '开', '广州', '镇', '粉丝', '最后', '带', '奔驰', '事', '新能源', '马化腾', '恒大', '三', '哪里', '阿里', '它', '版', '职业', '当', '影响', '比较', '阿里巴巴', '保罗', '大众', '即将', '穿', '已经', '重庆', '时间', 'F', '足球', '项目', 'IC', '机场', '原因', '发布', '世界杯', '京东', '凯尔特人', '明星', '款', '2017', '平台', '他们', '30', '吉利', '今年', '房', '地震', '们', '最大', '决赛', '国产', '学习', '认为', ':', '工作', '云', '看看', '体验', '武器', '视频', '12', '中超', '妈妈', '货币', '行业', '曝光', '滴滴', '管理', '卡', '服务', '海军', 'MSI', '专业', '家长', '最新', '球员', '卖', '金融', '股市', '安全', '全新', '家', '儿子', '亮相', '升级', '/', '成都', '战斗机', '宝骏', 'iPhone', '称', '农民', '现身', '深圳', '时候', '什么样', '开始', '小学', '娱乐圈', '很多', '旅行', '5G', '成功', '终于', '超', '复仇者', '你们', '适合', '英国', '50', '国内', '天', '使用', '跟', '真', '鸡', '创业', 'C', '最好', '路', '法国', '考试', '比亚迪', '觉得', 'LOL', '男', '香港', '不要', '只有', '大学生', '注意', '厉害', '王', '快', '标准', '今日', '超级', '计划', '最强', '故事', '11', '战场', '战队', '村']\n",
      "所有词的个数: 210541\n",
      "特征词个数: 4068\n",
      "训练集第一个文本词: ['上联', '：', '桃李春风', '一', '杯酒', '，', '如何', '对', '下联', '？']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "13\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      news_finance       0.75      0.67      0.70      8279\n",
      "        news_story       0.61      0.71      0.65      1905\n",
      "       news_travel       0.65      0.65      0.65      6409\n",
      "          news_edu       0.75      0.71      0.73      8159\n",
      "     news_military       0.76      0.71      0.74      7429\n",
      "         news_game       0.78      0.73      0.76      8810\n",
      "  news_agriculture       0.73      0.63      0.67      5780\n",
      "        news_house       0.79      0.76      0.77      5304\n",
      "       news_sports       0.89      0.85      0.87     11173\n",
      "          news_car       0.86      0.82      0.84     10700\n",
      "         news_tech       0.50      0.76      0.60     12668\n",
      "             stock       0.00      0.00      0.00       117\n",
      "news_entertainment       0.78      0.80      0.79     11658\n",
      "      news_culture       0.69      0.53      0.60      8335\n",
      "        news_world       0.68      0.61      0.65      8081\n",
      "\n",
      "          accuracy                           0.72    114807\n",
      "         macro avg       0.68      0.66      0.67    114807\n",
      "      weighted avg       0.74      0.72      0.72    114807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import os\n",
    "import random\n",
    "import jieba\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import joblib\n",
    "# 手写拉普拉斯修正的朴素贝叶斯\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    函数说明:中文文本处理\n",
    "    Parameters:\n",
    "        path - 文本存放的路径\n",
    "        test_size - 测试集占比，默认占所有数据集的百分之20\n",
    "    Returns:\n",
    "        all_words_list - 按词频降序排序的训练集列表\n",
    "        train_data_list - 训练集列表\n",
    "        test_data_list - 测试集列表\n",
    "        train_class_list - 训练集标签列表\n",
    "        test_class_list - 测试集标签列表\n",
    "\"\"\"\n",
    "def TextProcessing(path, test_size=0.3):\n",
    "#    folder_list = os.listdir(folder_path)  # 查看folder_path下的文件\n",
    "    data_list = []  # 数据集数据\n",
    "    class_list = []  # 数据集类别\n",
    "    with open(path, 'r', encoding='utf-8') as f:  # 打开txt文件\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split(\"_!_\") # 去除\"_!_\"\n",
    "            # print(line)\n",
    "            if (len(line) >= 5):\n",
    "                strr = line[3] + line[4]    # 有标题和关键词\n",
    "            else:\n",
    "                strr = line[3]  # 只有标题\n",
    "            word_cut = jieba.cut(strr, cut_all=False)  # 精简模式，返回一个可迭代的generator\n",
    "            word_list = list(word_cut)  # generator转换为list\n",
    "            data_list.append(word_list)\n",
    "            class_list.append(line[2])\n",
    "\n",
    "    data_class_list = list(zip(data_list, class_list))  # zip压缩合并，将数据与标签对应压缩\n",
    "    random.shuffle(data_class_list)  # 将data_class_list乱序\n",
    "    index = int(len(data_class_list) * test_size) + 1  # 训练集和测试集切分的索引值\n",
    "    train_list = data_class_list[index:]  # 训练集\n",
    "    test_list = data_class_list[:index]  # 测试集\n",
    "    train_data_list, train_class_list = zip(*train_list)  # 训练集解压缩\n",
    "    test_data_list, test_class_list = zip(*test_list)  # 测试集解压缩\n",
    "\n",
    "    all_words_dict = {}  # 统计训练集词频\n",
    "    for word_list in train_data_list:\n",
    "        for word in word_list:\n",
    "            if word in all_words_dict.keys():\n",
    "                all_words_dict[word] += 1\n",
    "            else:\n",
    "                all_words_dict[word] = 1\n",
    "\n",
    "    # 根据键的值倒序排序\n",
    "    all_words_tuple_list = sorted(all_words_dict.items(), key=lambda f: f[1], reverse=True)\n",
    "    all_words_list, all_words_nums = zip(*all_words_tuple_list)  # 解压缩\n",
    "    all_words_list = list(all_words_list)  # 转换成列表\n",
    "    \n",
    "    return all_words_list, train_data_list, test_data_list, train_class_list, test_class_list\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:读取文件里的内容，并去重\n",
    "Parameters:\n",
    "    words_file - 文件路径\n",
    "Returns:\n",
    "    words_set - 读取的内容的set集合\n",
    "\"\"\"\n",
    "def MakeWordsSet(words_file):\n",
    "    words_set = set()  # 创建set集合\n",
    "    with open(words_file, 'r', encoding='utf-8') as f:  # 打开文件\n",
    "        for line in f.readlines():  # 一行一行读取\n",
    "            word = line.strip()  # 去回车\n",
    "            if len(word) > 0:  # 有文本，则添加到words_set中\n",
    "                words_set.add(word)\n",
    "    return words_set  # 返回处理结果\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:文本特征选取\n",
    "Parameters:\n",
    "    all_words_list - 训练集所有文本列表\n",
    "    deleteN - 删除词频最高的deleteN个词\n",
    "    stopwords_set - 指定的结束语\n",
    "Returns:\n",
    "    feature_words - 特征集\n",
    "\"\"\"\n",
    "def words_dict(all_words_list, deleteN, stopwords_set=set()):\n",
    "    feature_words = []  # 特征列表\n",
    "    n = 1\n",
    "    for t in range(deleteN, len(all_words_list), 1):\n",
    "        if n > 5000:  # feature_words的维度为1000\n",
    "            break\n",
    "            # 如果这个词不是数字，并且不是指定的结束语，并且单词长度大于1小于5，那么这个词就可以作为特征词\n",
    "        if not all_words_list[t].isdigit() and all_words_list[t] not in stopwords_set and 1 < len(all_words_list[t]) < 5:\n",
    "            feature_words.append(all_words_list[t])\n",
    "        n += 1\n",
    "    return feature_words\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:根据feature_words将文本向量化\n",
    "Parameters:\n",
    "    train_data_list - 训练集\n",
    "    test_data_list - 测试集\n",
    "    feature_words - 特征集\n",
    "Returns:\n",
    "    train_feature_list - 训练集向量化列表\n",
    "    test_feature_list - 测试集向量化列表\n",
    "\"\"\"\n",
    "def TextFeatures(train_data_list, test_data_list, feature_words):\n",
    "    def text_features(text, feature_words):  # 出现在特征集中，则置1\n",
    "        text_words = set(text)\n",
    "        features = [1 if word in text_words else 0 for word in feature_words]\n",
    "        return features\n",
    "\n",
    "    train_feature_list = [text_features(text, feature_words) for text in train_data_list]\n",
    "    test_feature_list = [text_features(text, feature_words) for text in test_data_list]\n",
    "    # for features in train_feature_list:\n",
    "    #     for index in range(len(features)):\n",
    "    #         features[index]=str(index)+\"_\"+str(features[index])\n",
    "    # for features in test_feature_list:\n",
    "    #     for index in range(len(features)):\n",
    "    #         features[index]=str(index)+\"_\"+str(features[index])\n",
    "\n",
    "    return train_feature_list, test_feature_list  # 返回结果\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:新闻分类器\n",
    "Parameters:\n",
    "    train_feature_list - 训练集向量化的特征文本\n",
    "    test_feature_list - 测试集向量化的特征文本\n",
    "    train_class_list - 训练集分类标签\n",
    "    test_class_list - 测试集分类标签\n",
    "Returns:\n",
    "    test_accuracy - 分类器精度\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 文本预处理\n",
    "    folder_path = \"./toutiao_cat_data.txt\"  # 训练集存放地址\n",
    "    all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = TextProcessing(folder_path,test_size=0.3)\n",
    "    # 生成stopwords_set\n",
    "    stopwords_file = './stopwords_cn.txt'\n",
    "    stopwords_set = MakeWordsSet(stopwords_file)\n",
    "\n",
    "    test_accuracy_list = []\n",
    "\n",
    "    clf=MultinomialNB()\n",
    "\n",
    "    id2class=['news_finance', 'news_story', 'news_travel', 'news_edu', 'news_military', 'news_game', 'news_agriculture', 'news_house', 'news_sports', 'news_car', 'news_tech', 'stock', 'news_entertainment', 'news_culture', 'news_world']\n",
    "\n",
    "    class2id = {}\n",
    "    index = 0\n",
    "    for i in id2class:\n",
    "        class2id[i] = index\n",
    "        index = index + 1\n",
    "    # print(id2class)\n",
    "    train_class_list=[class2id[i] for i in train_class_list]\n",
    "    test_class_list = [class2id[i] for i in test_class_list]\n",
    "    feature_words = words_dict(all_words_list, 450, stopwords_set)\n",
    "    a = np.array(feature_words)\n",
    "    np.save(\"./feature_words.npy\", a)  # 保存为.npy格式\n",
    "    print(\"按词频降序排序的训练集列表:\",all_words_list[:450])\n",
    "    print('所有词的个数:',len(all_words_list))\n",
    "    print('特征词个数:',len(feature_words))\n",
    "    print('训练集第一个文本词:',train_data_list[0])\n",
    "    #print(feature_words)\n",
    "    train_feature_list, test_feature_list = TextFeatures(train_data_list, test_data_list, feature_words)\n",
    "    print(train_feature_list[0])\n",
    "    print(train_class_list[0])\n",
    "    clf.fit(train_feature_list,train_class_list)\n",
    "\n",
    "    joblib.dump(clf, \"./bayes.m\")\n",
    "\n",
    "    predict_y=clf.predict(test_feature_list)\n",
    "    print(classification_report(test_class_list, predict_y, target_names=id2class))\n",
    "    # acc = TextClassifier(train_feature_list, test_feature_list, train_class_list, test_class_list,c1)\n",
    "    # #print(c1.cc)\n",
    "    # #print(c1.fc)\n",
    "    # print(\"acc:\",acc)\n",
    "    # #print(\"predict lable:\",lable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
